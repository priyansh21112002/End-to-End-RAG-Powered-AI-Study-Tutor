{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from src.config import settings\n",
    "from src.models import TutorLLM\n",
    "from src.ingestion import VectorStoreManager\n",
    "from src.rag import create_retriever, RAGChain\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c0e6c",
   "metadata": {},
   "source": [
    "## 1. Test Document Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion import load_documents, chunk_documents, get_document_stats\n",
    "\n",
    "# Load sample documents (update paths as needed)\n",
    "docs = load_documents(\n",
    "    source_paths=[\"../data/raw/sample.pdf\"],  # Replace with actual PDF\n",
    "    subject=\"ML\"\n",
    ")\n",
    "\n",
    "# Get stats\n",
    "stats = get_document_stats(docs)\n",
    "print(f\"Documents loaded: {stats['total_documents']}\")\n",
    "print(f\"Total characters: {stats['total_characters']:,}\")\n",
    "\n",
    "# Chunk documents\n",
    "chunks = chunk_documents(docs)\n",
    "print(f\"\\nChunks created: {len(chunks)}\")\n",
    "print(f\"\\nSample chunk:\\n{chunks[0].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd89ced",
   "metadata": {},
   "source": [
    "## 2. Build Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector store\n",
    "vectorstore_manager = VectorStoreManager(collection_name=\"test_tutor\")\n",
    "\n",
    "# Build from chunks\n",
    "vectorstore_manager.build_vectorstore(chunks)\n",
    "\n",
    "# Get stats\n",
    "vs_stats = vectorstore_manager.get_stats()\n",
    "print(f\"Vector store stats:\")\n",
    "for key, value in vs_stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fa3a3",
   "metadata": {},
   "source": [
    "## 3. Test Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc703c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test similarity search\n",
    "query = \"What is gradient descent?\"\n",
    "results = vectorstore_manager.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"  Source: {doc.metadata.get('source_file', 'Unknown')}\")\n",
    "    print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2053b",
   "metadata": {},
   "source": [
    "## 4. Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297bd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (this will take a few minutes on first run)\n",
    "print(\"Loading LLM...\")\n",
    "llm = TutorLLM(use_quantization=True)\n",
    "\n",
    "# Print model info\n",
    "info = llm.get_info()\n",
    "print(\"\\nModel Info:\")\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c8257",
   "metadata": {},
   "source": [
    "## 5. Test RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82995bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = create_retriever(vectorstore_manager, k=5)\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = RAGChain(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    subject=\"ML\"\n",
    ")\n",
    "\n",
    "print(\"RAG chain ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = \"Explain overfitting and how to prevent it\"\n",
    "\n",
    "result = rag_chain.ask(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "print(f\"Inference time: {result['inference_time']}s\")\n",
    "print(f\"Sources used: {result['num_sources']}\")\n",
    "\n",
    "if result.get('sources'):\n",
    "    print(\"\\nSource citations:\")\n",
    "    for i, source in enumerate(result['sources'], 1):\n",
    "        print(f\"  {i}. {source['source']} (Page {source['page']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1d7ea",
   "metadata": {},
   "source": [
    "## 6. Test Practice Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag import PracticeQuestionGenerator\n",
    "\n",
    "generator = PracticeQuestionGenerator(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    subject=\"ML\"\n",
    ")\n",
    "\n",
    "questions = generator.generate(\n",
    "    topic=\"Neural Networks\",\n",
    "    num_questions=3\n",
    ")\n",
    "\n",
    "print(questions['questions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02249ed",
   "metadata": {},
   "source": [
    "## 7. Evaluate Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d520421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"What is the difference between supervised and unsupervised learning?\",\n",
    "    \"Explain backpropagation in simple terms\",\n",
    "    \"What is regularization and why is it important?\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question {i}: {q}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = rag_chain.ask(q)\n",
    "    print(f\"\\n{result['answer']}\")\n",
    "    print(f\"\\n[Time: {result['inference_time']}s, Sources: {result['num_sources']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647068b",
   "metadata": {},
   "source": [
    "## 8. Monitor VRAM Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"VRAM Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"VRAM Reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    print(f\"Max VRAM Used: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nCache cleared\")\n",
    "    print(f\"VRAM Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84574e",
   "metadata": {},
   "source": [
    "## 9. Experiment with Different Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2185cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG chains for different subjects\n",
    "subjects = [\"ML\", \"DL\", \"DSA\"]\n",
    "\n",
    "for subject in subjects:\n",
    "    chain = RAGChain(llm=llm, retriever=retriever, subject=subject)\n",
    "    result = chain.ask(f\"Give me a key concept in {subject}\")\n",
    "    \n",
    "    print(f\"\\n{subject}: {result['answer'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9377f3",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
